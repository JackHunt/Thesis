%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 

%% Tracking and Mapping.
\section{Tracking and Mapping}
\label{sec:lit_review_tam}
There has been much research in the field of Tracking and Mapping in recent 
years, with many large scale works being driven by the availibility of once 
costly depth sensing equipment. The availability of such equipment combined 
with the ever increasingly parallel nature of modern GPU's has seen the 
field advance greatly beyond the seminal but resource limited works of it's 
infancy. This advancement is most predominant within the Dense SLAM(Simultaneous 
Localisation and Mapping) literature. This section shall first explore the 
earlier, fundamental works of this area of research, followed by a treatment 
of the current state of the art.

\textit{Besl \& McKay} \cite{Besl1992} introduced their seminal work on 3D shape 
registration in 1992, providing a method to estimate full 6DoF(Six Degrees of 
Freedom) pose between 3D point sets. The authors present an Iterative Closest 
Point Algorithm that consists of three operations per iteration; computation 
of closest point, computation of a 6DoF Transformation and application of 
the Transformation. The authors present a proof of convergence based on that 
of Least Squares minimisation, however there must be sufficiently complex 
geometry present in the structure of the data to optimise to a meaningful 
Transformation.

Complementary to the aforementioned works of \textit{Besl \& McKay} \cite{Besl1992} 
in the foundational aspects of Dense SLAM is that of \textit{Curless \& Levoy} 
\cite{Curless1996}, 1996. The authors present an early volumetric integration 
framework for the reconstruction of shapes from range data obtained from a 
sensor such as a laser scanner. The authors introduce the SDF(Signed Distance Function), 
a volumetric, implicit shape representation in which entries are cumulatively updated 
in a weighted manner. Once observations have been integrated in to the SDF volume, an 
Isosurface representation of the shape is extracted by a Marching Cubes \cite{MC} 
procedure. Though the approach may lead to gaps in the resultant model, the authors 
mitigate this by introducing a Surface Tesselation step.

Later work by \textit{Zhou et al} \cite{Zhou2008} in 2008 introduces an alternative 
shape representation to that of \textit{Curless \& Levoy} \cite{Curless1996}, based 
on the spatial KD-Tree data structure and a highly data parallel BFS(Breadth First 
Search) construction algorithm. The level of parallelism introduced allows for 
application to problems that require real time performance. The authors provide 
examples of use in Ray Tracing \cite{RT} and Photon Mapping \cite{PM}.

In the same year, \textit{Censi} \cite{Censi2008} introduced \textit{PL-ICP}, a 
variant of the ICP algorithm introduced by \textit{Besl \& McKay} \cite{Besl1992}. 
The presented approach utilises a Point-to-Line metric rather than a Point-to-Point 
metric and has a closed form solution in the planar case. For the non planar case 
the presented approach acheives quadratic convergence in a finite number of steps, 
utilising a Normal weighting and a Lagrangian optimisation scheme. However, it is 
highlighted that prior to the optimisation procedure it is necessary to trim outliers 
from the point data sets.

Culminating much of the aforementioned work, in 2011 \textit{Newcombe et al} introduced 
the seminal \textit{KinectFusion} pipeline, allowing for real time mapping of indoor 
scenes with the Kinect RGBD sensor from Microsoft. The authors utilise a sparser form 
of the SDF structure introduced by \textit{Curless \& Levoy} \cite{Curless1996}, the 
TSDF(Truncated Signed Distance Function), allowing for reconstruction at scene scale. 
For pose estimation, a multi-level variant of the ICP algorithm utilising a Point-to-Plane 
metric similar to that of \textit{PL-ICP} \cite{Censi2008} is used. The pipeline consists 
of four phases; \textit{Measurement}, \textit{Integration}, \textit{Isosurface Extraction} 
and \textit{Pose Update}. Applications of the presented system however are limited only to 
those that require the reconstruction of static scenes; dynamic scenes are not supported 
by \textit{KinectFusion}.

Further optimisations were made in 2013 by \textit{Nei{\ss}ner at al} \cite{NieBner2013} to the 
\textit{KinectFusion} pipeline proposed by \textit{Newcombe et al}. The authors introduce a 
spatially hashed TSDF data structure, in which the TSDF is split in to hashed Voxel Blocks 
allowing for very fast Voxel lookups. The presented approach yields low space and time complexity 
for such operations, vastly increasing the potential for real time, large scale use. Additionally, 
a streaming system is introduced to dynamically handle data transmission between the CPU and GPU, 
allowing for the reconstruction of scenes that may exceed the GRAM bounds of commodity GPU's. The 
proposed system is capable of running at $\approx46Hz$ on an NVIDIA Titan GPU.

In the same year, \textit{Thomas et al} \cite{Thomas2013} introduced an alternative scene 
representation, based on the notion that a scene may be represented as a set of Planar 
components with attributes such as Surface Normals, confidences and RGB colour. The motivation 
of the author's approach is that many common scenes that one might reconstruct are indoors and 
consist of components that are planar in nature, such as walls, floors and ceilings. Additionally, 
many planar objects are common, such as tables and cabinets. The author presents an alternative 
rendering approach based on Quadrangulation \cite{QUAD} and utilise a \textit{KinectFusion} 
\cite{Newcombe2011} like ICP based algorithm for pose estimation.

\textit{Salas-Moreno et al} \cite{Salas-Moreno2013} in 2013 also, introduced another alternative 
approach to that of the \textit{KinectFusion} \cite{Newcombe2011} like pipelines that similarly to 
\textit{Thomas et al} \cite{Thomas2013}, utilises the prior information that many scenes consist 
of predictable, repeated structures. As such, the authors introduce a so called ``Object Oriented'' 
Dense SLAM paradigm, in which the reconstruction of the scene is split in to a graph of observed 
objects. Pose estimation is achieved by running an ICP based algorithm against renderings of the 
individual objects in the reconstructed scene model. Following pose estimation, the proposed 
system detects newly observed objects and inserts the appropriate object model in to the scene 
model. Consistency between scene components is enforced with Pose Graph Optimisation, with 
relocalisation achieved in a similar manner. The proposed approach does however require a 
database of known objects a-priori.

\textit{St{\"u}ckler et al} \cite{Stuckler2014} in 2014 introduced a non implicit, non volumetric 
representation based on multiple resolution Surfel \cite{Pfister2000} Maps. The core data structure 
used for scene representation is a Voxel Octree \cite{OCTREE} containing both Surfels and 
Probability Distributions over appearance and shape. Pose estimation is achieved by optimising for 
a Unit Quaternion \cite{QUAT} and Translation Vector within a Maximum Likelihood framework, in which 
the Energy Function to be maximised is the Likelihood of the RGBD observations given the accumulated 
Probability Distributions stored in the Octree. The presented pipeline also incorporates a randomised, 
graph and keyframe based loop closure component.

Following the approach of \textit{Thomas et al} \cite{Thomas2013}, \textit{Salas-Moreno et al} 
\cite{Salas-Moreno2014} in 2014 introduced another reconstruction system that utilises the
planarity property of many common scenes. The proposed approach focuses on the detection and 
modelling of planes in the scene, proceeding with their refinement over time. 
The proposed approach generates Surfel \cite{Pfister2000} Maps from observed RGBD frames, from 
which the planar regions are detected and integrated, filling holes in the reconstruction over time.
The authors utilise an ICP algorithm to register the vertex maps of the RGBD observations and the 
reconstructed model. Additionally, relocalisation is achieved by the use of Fern Encoding \cite{FERN}. 

\textit{Prisacariu et al} \cite{Prisacariu2014, Kahler2015} in 2014 followed up the optimisations 
to the \textit{KinectFusion} pipeline proposed by \textit{Nei{\ss}ner et al} \cite{NieBner2013}. 
The authors presented in addition to the original publication, a Technical Report and an Open 
Source implementation. The proposed further improvements to those of \textit{Nei{\ss}ner et al} 
\cite{NieBner2013} include a number of low level optimisations to the core Hashed TSDF data 
structure, it's allocation and update(integration of observation points) and the rendering 
phase of the pipeline. In addition, the authors demonstrate that pose estimation quality may 
be greatly improved by the use of commodity IMU(Inertial Motion Unit) devices, commonly found 
on mobile phones and tablet computers. \textit{Prisacariu et al} report runtimes of 
$\approx47Hz$ on an NVIDIA Shield Tablet and $\approx910Hz$ with a commodity NVIDIA Titan X GPU.

\textit{Whelan et al} \cite{Whelan2015} in 2015 proposed another \textit{KinectFusion} 
\cite{Newcombe2011} like pipeline intended to enable reconstruction of large scale scenes, 
acheiving reconstruction over hundreds of metres. The approach taken by the authors to enable 
such large scale reconstructions is centered around the use of a GPU Cyclic Buffer. For pose 
estimation, the authors impose both geometric and photometric constraints on the camera pose. 
Additionally, the proposed approach performs map updates in an as-rigid-as-possible \cite{ARAP} 
manner, combining frame recognition such that on a recognition event, a map update is performed.
The proposed pipeline provides loop closure capabilites by utilising Pose Graph Optimisation 
\cite{PGO}.

\textit{Zhou et al} \cite{Zhou2015} also in 2015 proposed another variant of the 
\textit{KinectFusion} \cite{Newcombe2011} pipeline proposed by \textit{Newcombe et al}. 
The authors present improvements on the pose estimation phase of the pipeline, utilising 
contour cues to aid association and enforcing correspondence constraints on the estimated 
pose, w.r.t scene geometry. Central to the presented approach is the depth image preprocessing 
steps of inpainting regions of the depth image for which there are no depth measurements, 
followed by the aforementioned contour extraction stage.

The optimised pipeline proposed in 2014 by \textit{Prisacariu et al} was in 2016 improved with 
the addition of loop closure handling by \textit{Kahler et al} \cite{Kahler2016}; \textit{Kahler} 
being one of the authors of the original 2014 contribution. Drift correction is acheived by the 
use of a multiple scene representation, with online alignment being performed periodically 
between the scenes. Corrections between the scenes are made via the use of Pose Graph Optimisation. 
Loop closures are detected by the use of Fern Conservatories \cite{GLOCKER}.

%% Semantic SLAM.
\section{Semantic SLAM}
Over the years there has been much interest within the Computer Vision research community on 
the Semantic understanding of our environment. The ability of machines to recognise and extract 
information about their environments and the components of them has wide application potential, 
ranging from autonomous robotics to augmented reality video games. The application potential 
of this Semantic Scene Understanding ability is amplified when it is combined with the vast 
progress that has been made in Dense SLAM. This section shall provide a survey of research 
that amalgamates the two fields of Semantic Scene Understanding and SLAM.

Bengio et.al. \cite{Bengio2013} - representation learning.
Girshick et.al \cite{Girshick2014} - feature hierarchies.

\label{sec:lit_review_semantic}
\textit{Civera et al} \cite{Civera2011} in 2011 introduced an approach to Semantic SLAM 
that utilises image based features to attach semantic meaning to 3D observations. The SLAM 
system itself is based on Monocular EKF SLAM with semantics added to points via 
correspondences between SURF image features extracted from the observed RGB frames and 
precomputed object descriptors. Consistency is then enforced by a geometric compatibility 
measure.

\textit{St{\"u}ckler et al} \cite{Stuckler2012} in 2012 presented a Semantic Dense SLAM 
pipeline for the object centric integration of RGBD images. Given an RGBD frame, objects 
are detected using a Random Forest classifier trained on hand crafted features extracted 
from RGBD images. The proposed approach does not reconstruct an entire scene, rather it 
reconstructs scene components(such as objects) that have been semantically segmented 
from the current RGBD frame.

\textit{Valentin et al} \cite{Valentin2015} in 2015 proposed a fully integrated Dense SLAM 
and Semantic Scene Understanding pipeline with interaction being a primary focus. The 
proposed pipeline at it's core is based on that of \textit{KinectFusion} \cite{Newcombe2011}, 
so requires the use of RGBD images and is restricted to the reconstruction of static scenes. 
Once a scene has been reconstructed, the author's pipeline allows users to interact with 
objects in the scene to provide training data for Streaming Random Forests\cite{Abdulsalam2007}, 
which are used to detect and label parts of the rendered Isosurface belonging to a given 
object class. Segmentations are refined using Variational Bayesian Mean Field Inference 
\cite{Xing2002} optimised by \cite{Krahenbuhl2011}. The features extracted for this training 
process are named \textit{Voxel Oriented Patch} features and consist of Surface Normals 
and CIELab appearance information.

\textit{Golodetz et al} \cite{Golodetz2015} in the same year released an Open Source 
implementation of the pipeline proposed by \textit{Valentin et al} \cite{Valentin2015}, 
utilising the implementation of the \textit{KinectFusion} \cite{Newcombe2011} pipeline 
provided by \textit{Prisacariu et al} \cite{Prisacariu2014}. The framework proposed by 
the authors extends that of \textit{Valentin et al} \cite{Valentin2015} greatly, for 
example by supporting the use of Motion Capture systems and Virtual Reality headsets. 
In addition, the implementation provided is optimised to allow for real time use.

\textit{Handa et al} \cite{Handa2015}, again in 2015 introduced an alternative, 
real time Dense Semantic SLAM pipeline. Much like the approaches of \textit{Valentin et al} 
\cite{Valentin2015} and \textit{Golodetz et al} \cite{Golodetz2015}, the proposed system 
is based on the \textit{KinectFusion} \cite{Newcombe2011} pipeline, with semantic scene 
understanding performed on the rendered Isosurface. Contrary to previous approaches however, 
the authors make use of stacked Deep Autoencoders \cite{DAA}, trained on synthetic depth 
images a priori. As such, the proposed system makes use only of depth cues and may not be 
adapted to new object classes on an ad-hoc basis.

\textit{Cavallari et al} \cite{Cavallari2016} in the following year presented another 
Semantic Dense SLAM pipeline built on top of the Dense SLAM system presented by 
\textit{Nei{\ss}ner et al} \cite{NieBner2013}. Much like the work of \textit{Handa et al} 
\cite{Handa2015}, the proposed approach depends on a model pretrained on a set of object 
classes. Unlike \textit{Handa et al} \cite{Handa2015}, the authors make use of an 
FCN(Fully Connected Network) \cite{FCN}, taking the PMF output to determine the class 
to be assigned to an Isosurface region.

%% Dynamic SLAM.
\section{Dynamic SLAM, Motion Segmentation and Optical Flow}
\label{sec:lit_review_dynamic}
Sections \ref{sec:lit_review_tam} and \ref{sec:lit_review_semantic} provided an assesment 
of pertinent literature on the topics of SLAM and Semantic SLAM. However, all of the 
aproaches outlined in these sections are limited to use in static scenes only without 
the capability to accurately operate in an environment that contains moving objects. This 
section shall explore pertinent literature on the topics of Dynamic SLAM, Motion Segmentation 
and Optical Flow. As such, the general focus of the work surveyed in this section is the 
detection, estimation and segmentation of motion in dynamic scenes.

\textit{Tsap et al} \cite{Tsap2000} in 2000 presented an Algorithm for nonrigid motion 
tracking of objects. The presented approach solves for dense motion Vector Fields between 
3D objects by modelling motion with Finite Elements. The proposed system analyses differences 
between actual and predicted behaviour, using iterative descent optimisation to find a set of 
optimal parameters for the nonlinear FEM(Finite Element Model). Additionally, pose estimation 
is improved by using point correspondences.

\textit{Chen et al} \cite{Chen2011} in 2011 introduced a system to perform nonrigid motion 
tracking of the human body. The proposed system extracts and skins a surface mesh from 
multi-view video, after being fitted with a skeleton prior. To solve for nonrigid, articulated 
motion, the authors utilise a Weighted Hierarchical ICP algorithm, where weightings are obtained 
by the Approximate Nearest Neighbour \cite{ANN} algorithm.

In the following year, \textit{Sun et al} \cite{Sun2012} proposed an approach to motion estimation 
for objects in images. The proposed approach performs Optical Flow in a layered manner, where each 
layer pertains to an object undergoing Rigid Body Motion, with the number of layers being determined 
automatically. The authors utilise Max Flow \cite{MAXFLOW} to solve as discretised flow field cost 
function for each layer, where object layers are a set of depth ordered MRF's(Markov Random Field).

\textit{Unger et al} \cite{Unger2012} again in 2012, proposed an alternative system for the 
estimation of motion of objects undergoing Rigid Body Motion in images. The authors present a 
Variational formulation for motion estimation and segmentation with occlusion handling. As with 
the contributions of \textit{Sun et al} \cite{Sun2012}, the authors utilise a parametric labelling 
of the flow field for each object undergoing motion, with labels encoded with an MRF Potts model.
However, contrary to \textit{Sun et al} \cite{Sun2012} who utilise a Max Flow algorithm over the 
MRF models, \textit{Unger et al} solved for flow and labels within a Primal-Dual based optimisation 
framework.

In the same year, \textit{Herbst et al} \cite{Herbst2013} proposed an extension to Optical 
Flow to 3D scenes; the proposed system solves for Scene Flow based on RGBD data. The proposed 
approach is similar to that of \textit{Brox et al} \cite{Brox2004}, with Scene Flow being 
formulated as a Variational Optimisation problem. The presented approach is a generalisation 
of the well established Variational Optical Flow algorithm of \textit{Brox et al} \cite{Brox2004}.

In the following year, \textit{St{\"u}ckler et al} \cite{Stueckler2013} presented a framework 
for the segmentation of Rigid Body Motion from RGBD data. The authors represent regions undergoing 
Rigid Body Motion and their associated motion parameters as latent variables, with the resultant 
segmentations and parameters being solve for within an EM(Expectation Maximisation) framework. 
The presented approach is robust to both simultaneous foreground and background motion by giving 
each parity.

Though the motion estimation and segmentation approaches reviewed up to this point have not 
been within the SLAM framework, \textit{Keller et al} \cite{Keller2013} in 2013 introduced an 
RGBD based Dense SLAM system capable of performing Motion Segmentation. Unlike the \textit{KinectFusion} 
\cite{Newcombe2011} inspired Dense SLAM pipelines, the presented approach does not utilise an 
implicit, volumetric representation. Rather, the authors opt for an explicit Surfel \cite{Pfister2000} 
based representation. Whilst performing live reconstruction, the proposed system detects and uses ICP 
outliers to determine dynamic scene components. With the information gained from detecting ICP outliers, 
the proposed system then propagates thses detections by a flood fill operation. As the proposed approach 
utilises an explicit, flat data structure for scene representation, it does not have advantages of 
it's highly optimised volumetric counterparts, such as that proposed by \textit{Prisacariu et al} 
\cite{Prisacariu2011}. As such, scalability is limited.

Perera et.al. \cite{Perera2015}
\begin{itemize}
	\item Motion segmentation in TSDF volumes,
	\item Based on MAP inference over a CRF on the TSDF.
	\item Can handle minor and major displacements.
	\item Motion labels and parameters found w.r.t. live frame and TSDF.
	\item $256^{3}$ voxel grid does not run real time. Scalability issues.
\end{itemize}

Newcombe et.al. \cite{Newcombe2015}
\begin{itemize}
	\item Handles non-rigidly deforming scenes.
	\item Built on KinectFusion pipeline.
	\item 6DoF motion field estimated that warps model to live frame.
	\item Warp field used to fuse new measurements in to canonical model.
	\item Warp field solved for by Dual Quaternion Blending. \cite{Kavan2006}
	\item Limitations, such as lack of robustness to open/closed topology changes(hands). Authors highlight scalability issues.
\end{itemize}

%% Object Reconstruction.
\section{Object Reconstruction}
\label{sec:lit_review_obj_recon}
Curless and Levoy \cite{Curless1996}
\begin{itemize}
	\item Object reconstruction from different viewpoints but statically.
	\item No pose tracking in the TAM sense.
\end{itemize}

Kolev et.al. \cite{Kolev2006}
\begin{itemize}
	\item Probabilistic 3D segmentation.
	\item Rather than direct reconstruction like Curless, the most probable image w.r.t. images is inferred.
	\item Level set representation used.
	\item Level set has analogous probability volume(pF,pB)
	\item Level set is evolved via a variational framework over probability volume.
	\item Only evaluated on synthetic data.
	\item Designed for objects with distinct appearance and homogeneous background, though some tolerance to noise is claimed.
\end{itemize}

Weise et.al. \cite{Weise2009}
\begin{itemize}
	\item 3D in hand scanning system.
	\item Point cloud representation, Surfel rendering. \cite{Pfister2000}
	\item Objects rotated in front of a sensor, suggests limited tracking ability.
	\item Drift offset in as-rigid-as-possible manner. %cite as-rigid-as-possible
	\item ICP registration. Topology graph used for deformation.
	\item Uses range scanner. No indication of RGBD capability. May need high quality equipment.
\end{itemize}

Ren et.al. \cite{Ren2013}
\begin{itemize}
	\item Probabilistic framework for tracking and reconstruction of objects.
	\item Initialised with a shape prior level set, which is then evolved as per observations.
	\item Works with RGBD data.
	\item Pixel-Wise-Posteriors used for segmentation. Prob volume like Kolev. \cite{Bibby2008}
	\item Experiments show limitations.
\end{itemize}

Dou et.al. \cite{Dou2015}
\begin{itemize}
	\item Reconstruction of deformable objects with a Kinect sensor.
	\item Loop closures automatically detected, distributing drift error over the loop.
	\item Latent shape and nonrigid deformation solved for with bundle adjustment.
	\item Surface represented as a triangular mesh.
	\item Experiments show high quality reconstructions, but with overnight run times.
\end{itemize}

Gupta et.al. \cite{Gupta2016}
\begin{itemize}
	\item 3D reconstruction and segmentation of objects with an RGBD sensor.
	\item Implicit representation, i.e. volumetric. Fusion with Softmax rather than weighted average like KF.
	\item Each voxel gets a label{obj, bg, empty}. Segmentation with graph cut and alpha expansion.
	\item Keyframe based loop closure.
	\item Pose estimation via photometric loss. Authors report drift to be a problem.
	\item Authors report difficulty in building a granular reconstruction.
\end{itemize}

%% Object Shape Prediction.
\section{Shape and Pose Prediction}
\label{sec:lit_review_prediction}

Prisacariu et.al. \cite{Prisacariu2011}
\begin{itemize}
	\item Shape prediction, segmentation(optimisation based) and pose optimisation.
	\item Hierarchical(early deep?) GPLVM's for Shape Latent Space Embedding. \cite{Lawrence2005}
	\item Unified energy function.
	\item Candidate shapes generated as one off regression in latent space.
\end{itemize}

Dame et.al. \cite{Dame2013}
\begin{itemize}
	\item Dense object reconstruction from monocular image source.
	\item Shape priors used to aid reconstruction and segmentation, GPLVM.
	\item Depth maps optimised for with Primal Dual with TV. Poses are known from PTAM.
\end{itemize}

Toshev et.al. \cite{Toshev2014}
\begin{itemize}
	\item Human pose estimation(articulated estimation) with Deep Neural Networks.
	\item Cascaded DNN regressors.
	\item No reconstruction, pose estimation only.
\end{itemize}

Wohlhart et.al. \cite{Wohlhart2015}
\begin{itemize}
	\item 3D object detection and pose recovery.
	\item CNN descriptors used with Nearest Neighbour Cost for detection and rough pose.
	\item Problem posed as KNN search in Descriptor Space.
	\item Object and Pose are coupled in training(i.e. two similar cars with different poses have distant descriptors)
\end{itemize}

Chang et.al. \cite{Chang2015}
\begin{itemize}
	\item Large scale dataset of 3D shapes.
	\item Synthetic data with no "source" sequence, i.e. no depth.
	\item Can be used to learn rich latent space embeddings.
\end{itemize}

Rock et.al. \cite{Rock2015}
\begin{itemize}
	\item Recovers a complete 3D model from a depth image of an object.
	\item Input depth image matched to database of objects via a Random Forest.
	\item Matched shape coarsely matched to depth map, then deformed at a higher granularity.
	\item Deformation manually optimised for.
\end{itemize}

Zhou et.al. \cite{Zhou2017_2}
\begin{itemize}
	\item Object detection from 3D Point Clouds.
	\item End-to-end trainable Convolutional, Region Proposal Network.
	\item Trained on KITTI LIDAR dataset. \cite{Geiger2013}
	\item Voxelisation of point cloud used for region detections.
\end{itemize}

Gwak et.al \cite{Gwak2017}
\begin{itemize}
	\item GAN like shape prediction with log-barrier ojective.
	\item Weakly supervised with sillhouettes and 3D shapes.
	\item May not work "in the wild"
\end{itemize}

