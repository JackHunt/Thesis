\section{Introduction}
~\label{sec:spp_introduction}
% Object reconstruction requires full view of object
% Relevant background - pose regression, shape regression
% In the wild, RGBD won't work, hence stereo.
% 

\section{Related Work}
~\label{sec:spp_related}

\section{Algorithmic Overview}
~\label{sec:spp_algorithm}
\subsection{Gaussian Process Marginal Likelihood}
~\label{subsec:spp_gp_marginal_likelihood}
Given a Latent Variable Model of the following form
\begin{equation}
  \label{eqn:spp_gp_lvm}
  P(\bm{Y} \given \bm{X}, \bm{W}, \beta) = P(\bm{Y} \given \bm{WX}^{T}, \beta^{-1}\bm{I})
\end{equation}
Where in Equation~\ref{eqn:spp_gp_lvm} the observed data \(\bm{Y} \in \mathbb{R}^{N \times D}\) 
is mapped to a lower dimensionality manifold \(\bm{X} \in \mathbb{R}^{N \times P}\), by parameters 
\(\bm{W} \in \mathbb{R}^{P \times D}\) and variance \( \beta \).

The marginal likelihood of \(\bm{X}\) is of the form outlined in Equation~\ref{eqn:spp_gp_marginal}.
\begin{equation}
  \label{eqn:spp_gp_marginal}
  P(\bm{Y} \given \bm{X}, \beta) = \int P(\bm{Y} \given \bm{X}, \bm{W}, \beta) P(\bm{W}) \intd{\bm{W}}
\end{equation}
Where in Equation~\ref{eqn:spp_gp_marginal}, \(P(\bm{W})\) is a Gaussian conjugate prior of the 
form \(\mathcal{N}(\bm{W} \given \bm{0}, \bm{I})\).

To find the marginal distribution outlined in Equation~\ref{eqn:spp_gp_marginal}, it's form may 
be simplified as follows in Equation~\ref{}.

\begin{align}
  \label{eqn:spp_gp_marginal_simplify}
  % Line 1.
  P(\bm{Y} \given \bm{X}, \beta) ={}& \int \mathcal{N}(\bm{Y} \given \bm{WX}^{T}, \beta^{-1}\bm{I})
  \mathcal{N}(\bm{W} \given \bm{0}, \bm{I}) \intd{\bm{W}} \\
  % Line 2.
  =& \int \frac{1}{\sqrt{\left|2\pi\beta^{-1}\bm{I}\right|}} e^{ 
    -\frac{\beta}{2} {\big( \bm{Y} - \bm{WX} \big)}^{T} \big( \bm{Y} - \bm{WX} \big) 
  }
  \frac{1}{\sqrt{\left|2\pi\bm{I}\right|}} e^{ 
    -\frac{1}{2} \bm{W}^{T}\bm{W}} \intd{\bm{W}} \\
  % Line 3.
  =& \frac{1}{\sqrt{\left|2\pi\beta^{-1}\bm{I}\right|}} \frac{1}{\sqrt{\left|2\pi\bm{I}\right|}} 
  \int e^{
    -\frac{\beta}{2} {\big( \bm{Y} - \bm{WX} \big)}^{T} \big( \bm{Y} - \bm{WX} \big) 
    -\frac{1}{2} \bm{W}^{T}\bm{W}} \intd{\bm{W}} \\
  % Line 4.
  \propto& \int e^{
    -\frac{\beta}{2} {\big( \bm{Y} - \bm{WX} \big)}^{T} \big( \bm{Y} - \bm{WX} \big) 
    -\frac{1}{2} \bm{W}^{T}\bm{W}} \intd{\bm{W}} \\
  % Line 5.
  \propto& \int e^{ 
  -\frac{1}{2} \Big[
    \beta {\big( \bm{Y} - \bm{X}^{T}\bm{W} \big)}^{T} \big( \bm{Y} - \bm{X}^{T}\bm{W} \big) 
    + \bm{W}^{T}\bm{W}
  \Big]} \intd{\bm{W}} \\
  % Line 6.
  \propto& e^{ -\frac{\beta}{2} \bm{Y}^{T}\bm{Y}} 
  \int e^{
  -\frac{1}{2} \Big[
    -\beta \big( \bm{Y}^{T}\bm{X}^{T}\bm{W} \big) 
    -\beta {\big( \bm{W}^{T}\bm{XY} \big)}^{T}
    +\beta \bm{W}^{T}\bm{XX}^{T}\bm{W}
    + \bm{W}^{T}\bm{W}\Big]} \intd{\bm{W}} \\
  % Line 7.
  \propto& e^{-\frac{\beta}{2} \bm{Y}^{T}\bm{Y}} 
  \int e^{
  -\frac{1}{2} \Big[
    -2\beta \bm{Y}^{T}\bm{X}^{T}\bm{W}
    +\beta \bm{W}^{T}\bm{XX}^{T}\bm{W}
    + \bm{W}^{T}\bm{W}
  \Big]} \intd{\bm{W}} \\
  % Line 7.
  \propto& e^{-\frac{\beta}{2} \bm{Y}^{T}\bm{Y}} 
  \int e^{
  -\frac{1}{2} \Big[
    \bm{W}^{T} \big( \beta \bm{XX}^{T} + \bm{I} \big) \bm{W}
    -2\beta \bm{Y}^{T}\bm{X}^{T}\bm{W}
  \Big]} \intd{\bm{W}}
\end{align}

To make the integral over \(\bm{W}\) tractable in Equation~\ref{eqn:spp_gp_marginal_simplify}, 
the distribution \(P(\bm{Y} \given \bm{X}, \beta)\) must be of a Gaussian form; an exponential 
of a quadratic form. Completing the square in \(\bm{W}\) allows the marginal to be expressed 
in such a form. First, making the change of variables as in Equation 
~\ref{eqn:spp_gp_marginal_change}, the procedure is as follows in Equation~\ref{eqn:spp_gp_complete}.

\begin{align}
  \label{eqn:spp_gp_marginal_change}
  \bm{A} ={}& \beta \bm{XX}^{T} + \bm{I}\\
  \bm{b} =& \beta \bm{Y}^{T} \bm{X}^{T}
\end{align}
a
\begin{align}
  \label{eqn:spp_gp_complete}
  % Line 1.
  P(\bm{Y} \given \bm{X}, \beta) \propto{}& e^{-\frac{\beta}{2}\bm{Y}^{T}\bm{Y}}
  \int e^{-\frac{1}{2} 
  \big[
    \bm{W}^{T}\bm{AW} - 2\bm{bW}  
  \big]} \intd{\bm{W}}\\
  % Line 2.
  \propto& e^{-\frac{\beta}{2}\bm{Y}^{T}\bm{Y}}
  \int e^{ 
    -\frac{1}{2} \bm{W}^{T}\bm{AW} 
    - 2\bm{bW} 
    - \bm{b}^{T}\bm{A}^{-1}\bm{b}} \intd{\bm{W}}\\
  % Line 3.
  \propto& e^{-\frac{\beta}{2}\bm{Y}^{T}\bm{Y}}
  \int e^{ 
    -\frac{1}{2} \bm{W}^{T}\bm{AW} 
    - 2\bm{bA}\bm{A}^{-1}\bm{W}
    + \bm{b}^{T}\bm{A}^{-1}\bm{AA}^{-1}\bm{b}} \intd{\bm{W}}\\
  % Line 4.
  \propto& e^{-\frac{\beta}{2}\bm{Y}^{T}\bm{Y}}
  \int e^{-\frac{1}{2} \big[ 
      {\big( \bm{W} - \bm{A}^{-1}\bm{b} \big)}^{T}
      \bm{A}
      \big( \bm{W} - \bm{A}^{-1}\bm{b} \big)
      - \bm{b}^{T}\bm{A}^{-1}\bm{b}
    \big]} \intd{\bm{W}}\\
  % Line 5.
  \propto& e^{-\frac{\beta}{2}\bm{Y}^{T}\bm{Y}}
  e^{-\frac{1}{2} \big[
      \sqrt{\left| 2 \pi \bm{A} \right|}
      - \bm{b}^{T}\bm{A}^{-1}\bm{b}
    \big]}\\
  % Line 6.
  \propto& e^{\frac{1}{2} \big[
    \beta \bm{Y}^{T} \beta \bm{Y}
    - \bm{b}^{T}\bm{A}^{-1}\bm{b}
    \big]}\\
  % Line 7.
  \propto& e^{-\frac{1}{2}
  \bm{Y}^{T} \big(
    \beta \bm{I} - \beta^{2}\bm{X}^{T}\bm{A}^{-1}\bm{X}
    \big)\bm{Y}}
\end{align}

With the distribution \(P(\bm{Y} \given \bm{X}, \beta)\) derived as being proportional to  
an exponentiated quadratic form as in Equation~\ref{eqn:spp_gp_complete}, it is 
clear that the inverse covariance matrix \(\bm{\Sigma}^{-1}\) of the Gaussian distribution 
corresponding to \(P(\bm{Y} \given \bm{X}, \beta)\) is as follows in Equation 
~\ref{eqn:spp_sig_inv}.
\begin{align}
  \label{eqn:spp_sig_inv}
  % Line 1.
  \bm{\Sigma}^{-1} ={}& \beta \bm{I} - \beta^{2} \bm{X}^{T} \bm{A}^{-1} \bm{X}\\
  % Line 2.
  =& \beta \bm{I} - \beta^{2} \bm{X}^{T} {\big(\beta \bm{XX}^{T} + \bm{I} \big)}^{-1}
\end{align}

To obtain the covariance matrix of the distribution \(P(\bm{Y} \given \bm{X}, \beta)\), the 
form if it's inverse may be simplified by the use of the Matrix Inversion Lemma (also known 
as the Woodbury Identity)~\cite{}. First making the change of variables in the Woodbury Identity 
as in Equation~\ref{eqn:spp_woodbury}.
\begin{align}
  % Variable change.
  \label{eqn:spp_sig_inv_simp}
    \bm{A} ={}& \beta^{-1}\bm{I}\\
    \bm{C} =& \bm{I}\\
    \bm{U} =& \bm{X}^{T}\\
    \bm{V} =& \bm{X}
  \shortintertext{in}
  % Woodbury.
  (\bm{A} + \bm{UCV}) =&
  \bm{A}^{-1} - \bm{A}^{-1}\bm{U} 
  {(\bm{C}^{-1} + \bm{VA}^{-1}\bm{U})}^{-1}
  \bm{VA}^{-1}
\end{align}
The simplified form of \( \bm{\Sigma}^{-1} \) is derived as follows in 
Equation~\ref{eqn:spp_sig_inv_simp}.

\begin{align}
  \label{eqn:spp_sig_inv_simp}
  % Line 1.
  \bm{\Sigma}^{-1} ={}& \beta \bm{I} - \beta^{2} \bm{X}^{T} 
  {\big(\beta \bm{XX}^{T} + \bm{I} \big)}^{-1}\\
  % Line 2.
  =& \beta^{-1} \bm{I} + \bm{X}^{T}\bm{X}
\end{align}

It follows from Equation~\ref{eqn:spp_sig_inv_simp}, that the covariance matrix \( \bm{\Sigma} \)
takes the following form.
\begin{align}
  \label{eqn:spp_sig}
  % Line 1.
  \bm{\Sigma} ={}& {(\bm{\Sigma}^{-1})}^{-1}\\
  % Line 2.
  =& \bm{X}^{T}\bm{X} + \beta^{-1}\bm{I}
\end{align}

So the form of the marginal likelihood \(P(\bm{Y} \given \bm{X}, \beta)\) is given in 
Equation~\ref{eqn:spp_gp_marginal_simp}
\begin{align}
  \label{eqn:spp_gp_marginal_simp}
  % Line 1.
  P(\bf{Y \given \bm{X}, \beta}) ={}& \mathcal{N}(\bm{Y} \given \bm{0}, 
  \bm{X}^{T}\bm{X} + \beta^{-1}\bm{I})\\
  % Line 2.
  =& TODO
\end{align}

To find the most probable latent space embedding, the latent variables \( \bm{X} \) may be 
found by directly optimising the marginal likelihood of Equation~\ref{eqn:spp_gp_marginal_simp}. 
As such, the narural logarithm
\begin{align}
  \label{eqn:spp_gp_marginal_log}
  % Line 1.
  \mathcal{L} ={}& -\frac{DN}{2} \ln(2\pi)
  -\frac{D}{2} \ln(\left| \bm{\Sigma} \right|)
  -\frac{1}{2} \text{tr}(\bm{\Sigma}^{-1} \bm{YY}^{T})\\
  % Line 2.
  =& -\frac{DN}{2} \ln(2\pi)
  -\frac{D}{2} \ln(\left| \bm{\Sigma} \right|)
  -\frac{1}{2} \bm{Y}^{T}\bm{\Sigma}\bm{Y}
\end{align}

The gradient of the log marginal of Equation~\ref{eqn:spp_gp_marginal_log} 
is derived as follows in Equation~\ref{eqn:spp_gp_log_marginal_grad}.
\begin{align}
  \label{eqn:spp_gp_log_marginal_grad}
  % Line 1.
  \frac{\partial \mathcal{L}}{\partial \bm{X}} ={}&
  -\frac{1}{2} \Bigg[
    \Big( D \frac{\partial}{\partial \bm{\Sigma}} 
    \ln \big( \left| \bm{\Sigma} \right| \big) \Big) 
    \frac{\partial \bm{\Sigma}}{\partial \bm{X}}
    + \Big( \frac{\partial}{\partial \bm{\Sigma}}
    \bm{Y}^{T} \bm{\Sigma}^{-1} \bm{Y} \Big)
    \frac{\partial \bm{\Sigma}}{\partial \bm{X}}
  \Bigg]\\
  % Line 2.
  =& -\frac{1}{2} \Bigg[
    D \bm{\Sigma}^{-1} \frac{\partial \bm{\Sigma}}{\partial \bm{X}}
    - \bm{\Sigma}^{-1} \bm{YY}^{T} \bm{\Sigma}^{-1} 
    \frac{\partial \bm{\Sigma}}{\partial \bm{X}}
  \Bigg]\\
  % Line 3.
  =& -\frac{1}{2} \Bigg[
    D \bm{\Sigma}^{-1} 2 \bm{X}
    - \bm{\Sigma}^{-1} \bm{YY}^{T} \bm{\Sigma}^{-1} 2 \bm{X}
  \Bigg]\\
  % Line 4.
  =& -D \bm{\Sigma}^{-1} \bm{X}
  + \bm{\Sigma}^{-1} \bm{YY}^{T} \bm{\Sigma}^{-1} \bm{X}
\end{align}

\section{Qualitative Results}
~\label{sec:spp_qualitative}

\section{Quantitative Results}
~\label{sec:spp_quantitative}