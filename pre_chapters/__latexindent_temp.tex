Advances in 3-dimensional (3D) computer vision have tremendously impacted the way that humans and computers interact. 
Applications of 3D vision, such as virtual reality video games and robotics are underpinned by a range of 
computer vision competencies, including pose estimation, mapping and semantic understanding. However, 
many challenging research problems remain, three of which are the focus of this work.

Firstly, the difficult task of dense mapping in dynamic environments is tackled, utilising a 
novel scene representation allowing dynamic and static components to be handled separately. This approach demonstrates improved 
pose estimation accuracy in dynamic scenes, compared to established reconstruction approaches. The second topic of this Thesis is 3D object reconstruction, with a novel representation and formulation that provides 
online error correction. This approach demonstrates improved reconstruction quality and geometric accuracy compared to both 
a start of the art method and a vanilla approach. The final focus of this work is the simultaneous inference of object shape and pose in large scale, outdoor environments. 
This approach regresses shape and pose in a weakly-supervised manner, utilising a combination of Convolutional Neural Networks 
and Gaussian Processes. Early results indicate\dots

This Thesis provides a foundation for further research in this area. However, immediate applications are evident. The motion segmentation and dense mapping approach allows for operation 
in previously prohibitive scenarios, such as robotics. The 3D object reconstruction work is applicable to the collection of 
geometrically consistent 3D object data. Finally, the simultaneous inference of shape and pose is applicable to modelling scenarios of 
specific semantic interest, where an entire scene need not be reconstructed, preliminarily demonstrating potential for large 
scale, semi-dense, geometric mapping.